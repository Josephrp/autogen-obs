TL;DR: This article provides a demonstration of how to use autogen for local LLM application using FastChat and ChatGLMv2-6b. The article covers preparations, cloning FastChat and downloading the checkpoint for ChatGLM-6B. It also includes instructions for initiating the server and interacting with the model using oai.Completion. Lastly, it explains how to interact with multiple local LLMs on your machine.